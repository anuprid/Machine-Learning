{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Classification with Logistic Regression and SVM\n",
    "\n",
    "Before we start, please put your name and CUID in following format\n",
    "\n",
    ": Firstname LASTNAME, #00000000   //   e.g. Nianyi LI, #12345678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**   \n",
    "Your NAME, #XXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Rules of the Project Submission\n",
    "\n",
    "Python 3 and [Matplotlib](https://matplotlib.org/) will be used throughout the semseter, so it is important to be familiar with them. It is strongly suggested to go through [Stanford CS231n](http://cs231n.github.io/python-numpy-tutorial/) and [CS228](https://github.com/kuleshov/cs228-material/blob/master/tutorials/python/cs228-python-tutorial.ipynb) for more detailed Python and numpy tutorials if you haven't had used Python before. \n",
    "\n",
    "In some cells and files you will see code blocks that look like this:\n",
    "\n",
    "```python\n",
    "##############################################################################\n",
    "#                    TODO: Write the equation for a line                     #\n",
    "##############################################################################\n",
    "pass\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################\n",
    "```\n",
    "\n",
    "You should replace the `pass` statement with your own code and leave the blocks intact, like this:\n",
    "\n",
    "```python\n",
    "##############################################################################\n",
    "#                    TODO: Write the equation for a line                     #\n",
    "##############################################################################\n",
    "y = m * x + b\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################\n",
    "```\n",
    "\n",
    "When completing the notebook, please adhere to the following rules:\n",
    "- Do not write or modify any code outside of code blocks\n",
    "- Follow the instruction of the project description carefully\n",
    "- Run all cells before submitting. <span style=\"color:red\">**You will only get credit for code that has been run!**.</span>\n",
    "\n",
    "The last point is extremely important and bears repeating:\n",
    "\n",
    "### We will not re-run your notebook -- <span style=\"color:red\">you will only get credit for cells that have been run</span>\n",
    "\n",
    "### File name\n",
    "Your Python program should be named **yourlastname_yourfirstname_P3.ipynb**, then zip it and upload to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "For this project we will apply both **Logistic Regression** and **SVM** to predict whether capacitors from a fabrication plant pass quality control based (QC) on two different tests. To train your system and determine its reliability you have a set of 118 examples. The plot of these examples is show below where a red x is a capacitor that failed QC and the green circles represent capacitors that passed QC.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://nianyil.people.clemson.edu/CPSC_4430/P3_new.png\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two text files with the data is available on Canvas: a training set of 85 examples and a test set of 33 examples. Both are formatted as\n",
    "- First line: **m** and **n**, tab separated\n",
    "- Each line after that has two real numbers representing the results of the two tests, followed by a *1.0* if the capacitor *passed* QC and a *0.0* if it *failed* QCâ€”tab separated.\n",
    "\n",
    "You need to write a code to read data from the file. You **can** use packages, such as **panda**, to load the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#         TODO: Write the code for reading data from file                    #\n",
    "##############################################################################\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "x1, x2, y = np.loadtxt('P3train.txt', skiprows = 1, unpack = True)\n",
    "t_x1, t_x2, t_y = np.loadtxt('P3test.txt', skiprows = 1, unpack = True)\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13191   -0.51389  ]\n",
      " [ 0.29896    0.61915  ]\n",
      " [ 0.13767    0.57529  ]\n",
      " [ 0.82316    0.27558  ]\n",
      " [ 0.59274   -0.7405   ]\n",
      " [ 0.50634    0.75804  ]\n",
      " [-0.13306   -0.4481   ]\n",
      " [-0.4038     0.70687  ]\n",
      " [-0.74366   -0.25804  ]\n",
      " [-0.13882    0.54605  ]\n",
      " [-0.092742   0.68494  ]\n",
      " [-0.17339    0.64839  ]\n",
      " [-0.29435    0.77997  ]\n",
      " [-0.60541    0.59722  ]\n",
      " [-0.59965   -0.41886  ]\n",
      " [ 0.63882    0.88962  ]\n",
      " [-0.375      0.50219  ]\n",
      " [ 0.28744   -0.76974  ]\n",
      " [-0.69758    0.68494  ]\n",
      " [ 0.73675   -0.18494  ]\n",
      " [-0.72062    0.53874  ]\n",
      " [-0.50749    0.90424  ]\n",
      " [ 0.60426    0.59722  ]\n",
      " [-0.28859   -0.060673 ]\n",
      " [ 0.22408    0.77997  ]\n",
      " [ 0.38537   -0.56506  ]\n",
      " [ 0.54666    0.48757  ]\n",
      " [ 0.22984   -0.41155  ]\n",
      " [ 0.2932    -0.2288   ]\n",
      " [-0.092742   0.55336  ]\n",
      " [-0.62846    0.33406  ]\n",
      " [ 0.76555    0.50219  ]\n",
      " [ 0.86348   -0.082602 ]\n",
      " [-0.28283    0.47295  ]\n",
      " [-0.52477    0.2098   ]\n",
      " [-0.39804    0.034357 ]\n",
      " [-0.43836    0.21711  ]\n",
      " [-0.54781    0.70687  ]\n",
      " [ 0.92684    0.3633   ]\n",
      " [-0.49021   -0.3019   ]\n",
      " [ 0.89804   -0.20687  ]\n",
      " [-0.13882   -0.27266  ]\n",
      " [ 0.67339   -0.53582  ]\n",
      " [ 0.20104   -0.60161  ]\n",
      " [-0.20795    0.17325  ]\n",
      " [-0.38076    0.91886  ]\n",
      " [-0.66302   -0.21418  ]\n",
      " [-0.26555    0.96272  ]\n",
      " [ 0.48329   -0.18494  ]\n",
      " [ 0.28744    1.087    ]\n",
      " [ 0.82892   -0.5212   ]\n",
      " [-0.48445    0.99927  ]\n",
      " [ 0.57546    0.26827  ]\n",
      " [-0.46717   -0.13377  ]\n",
      " [-0.69758    0.041667 ]\n",
      " [-0.21947   -0.016813 ]\n",
      " [-0.046659  -0.57968  ]\n",
      " [ 0.46025    0.012427 ]\n",
      " [ 0.63882   -0.24342  ]\n",
      " [ 0.46601   -0.41886  ]\n",
      " [ 0.085829  -0.75512  ]\n",
      " [ 0.051267   0.69956  ]\n",
      " [ 0.322      0.5826   ]\n",
      " [ 0.82316    0.66301  ]\n",
      " [ 0.6273     0.15863  ]\n",
      " [ 0.93836    0.012427 ]\n",
      " [-0.081221   1.1089   ]\n",
      " [-0.06394   -0.18494  ]\n",
      " [ 0.44297    0.67032  ]\n",
      " [-0.30012    0.027047 ]\n",
      " [-0.42108   -0.27266  ]\n",
      " [-0.40956   -0.41155  ]\n",
      " [-0.61118   -0.067982 ]\n",
      " [-0.75518    0.2902   ]\n",
      " [-0.0063364  0.39985  ]\n",
      " [ 0.10311    0.77997  ]\n",
      " [-0.23675   -0.63816  ]\n",
      " [-0.36348    0.31213  ]\n",
      " [ 0.22408    0.52412  ]\n",
      " [ 0.39689    0.82383  ]\n",
      " [-0.59389    0.005117 ]\n",
      " [ 0.63265   -0.030612 ]\n",
      " [-0.046659   0.81652  ]\n",
      " [-0.16187    0.8019   ]\n",
      " [-0.0063364  0.99927  ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.column_stack([x1,x2])\n",
    "X = np.matrix(x)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your assignment is to use what you have learned from the class slides and homework to create (**from scratch in Python**, not by using Logistic Regression library function!) a **Logistic Regression** and **SVM** binary classifier to predict whether each capacitor in the test set will pass QC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are free to use any model variation and any testing or training approach we have discussed for logistic regression. In particular, since this data is not linear, I assume you will want to add new features based on power of the original two features to create a good decision boundary. $w_0 + w_1x_1 + w_2x_2$ is not going to work!\n",
    "One choice might be\n",
    "- $\\textbf{w}^T \\textbf{x} = w_0 + w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 + w_5x_5 +w_6x_6 + w_7x_7 + w_8x_8$    where the new features are created as follows:\n",
    "\n",
    "| New Features |From Original Features |\n",
    "| --- | --- |\n",
    "|$x_1$\t| $x_1$|\n",
    "|$x_2$\t| $x_1^2$|\n",
    "|$x_3$\t| $x_2$||\n",
    "|$x_4$\t| $x_1x_2$|\n",
    "|$x_5$\t| $x_1x_2^2$|\n",
    "|$x_6$\t| $x_2^2$|\n",
    "|$x_7$\t| $x_1^2x_2$|\n",
    "|$x_8$\t| $x_1^2x_2^2$|\n",
    "\n",
    "Note that it is easy to create a small Python program that reads in your  original features, uses a nested loop to create the new features and then writes them to a file:\n",
    "\n",
    "```python\n",
    "thePower = 2\n",
    "for j in range(thePower+1): \n",
    "    for i in range(thePower+1):\n",
    "        temp = (x1**i)*(x2**j)\n",
    "        if (temp != 1):\n",
    "            fout1.write(str(temp)+\"\\t\") fout1.write(str(y)+\"\\n\")\n",
    "```\n",
    "\n",
    "With a few additions to the code, you can make a program to create combinations of any powers of $x_1$ and $x_2$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#           TODO: Define the Logistic regression models                      #\n",
    "##############################################################################\n",
    "def logistic_model():\n",
    "    e_z = np.exp(-(compute_wTx(x1, x2, w)))\n",
    "    g_z = 1 / (1 + (e_z))\n",
    "    return g_z\n",
    "def compute_wTx(x1, x2, w):\n",
    "    wTx = (\n",
    "        w[0] + \n",
    "        w[1] * x1 + \n",
    "        w[2] * x1**2 + \n",
    "        w[3] * x2 + \n",
    "        w[4] * x1 * x2 + \n",
    "        w[5] * x1 * x2**2 + \n",
    "        w[6] * x2**2 + \n",
    "        w[7] * x2 * x1**2 + \n",
    "        w[8] * (x1**2) * (x2**2)\n",
    "    )\n",
    "    return wTx\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization using Gradient Decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have defined the logistic regression model, you need to find the weights using the Gradient Decent algorithm. You need to implement the Vanilla Gradient Decent from scratch in Python.\n",
    "\n",
    "You need to specify the hyperparameters of GD, and plot the training loss curve (**J-curve**). The loss function should be the binary cross-entropy loss function that we introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4250092216.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    epoch_num = pass\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "#           TODO: Implement the Gradient Decent Algorithm                    #\n",
    "##############################################################################\n",
    "# Define the hyperparameters:\n",
    "# Numbers of epoch (epoch_num), learning rate (lr), and the initial weights(w)\n",
    "epoch_num = pass\n",
    "lr = pass\n",
    "w = pass\n",
    "J = pass\n",
    "\n",
    "# Define the loss:\n",
    "def cross_entropy_loss(y_pred,y):\n",
    "    m = len(y)\n",
    "    J = -(1/m) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "    return J\n",
    "\n",
    "# Calculate the gradient function:\n",
    "def gradient_func(J,w):\n",
    "    \n",
    "    return gradient_value\n",
    "    \n",
    "# Implement the Gradient decent algorithm using for loop\n",
    "def Vanilla_GD(epoch_num,lr,w,J):\n",
    "    for epoch in range(epoch_num):\n",
    "        x = np.column_stack([x1,x2])\n",
    "        X = np.matrix(x)\n",
    "        # Make predictions\n",
    "        z = np.dot(X, w)\n",
    "        y_pred = sigmoid(z)\n",
    "        \n",
    "        # Calculate the gradient\n",
    "        gradient = gradient_func(J,w)\n",
    "        \n",
    "        # Update the weights\n",
    "        w = w - lr * gradient           \n",
    "    return w\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, print out the final weights and plot the **J-curve/Loss curve** of training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                     TODO: Plot the J curve                                 #\n",
    "##############################################################################\n",
    "# Print out the final weights\n",
    "print(w)\n",
    "\n",
    "# Plot the J curve w.r.t. the iteration numbers\n",
    "plt.plot(range(epoch_num), cost)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('J-Curve / Loss Curve of Training')\n",
    "plt.show()\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your data and plot, you should then briefly discuss how you can ensure that the model is well trained.\n",
    "\n",
    "**Your Answer:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance on testing set:\n",
    "- Print out the confusion matrix\n",
    "- Calculate and print out the *accuracy*, *precision*, *recall*, and *F1* value of your model\n",
    "\n",
    "**Note that:**\n",
    "- For **undergrads** *(CPSC 4430)* the final accuracy of both algorithms on your test set should be higher than  <span style=\"color:red\">**70%**</span>\n",
    "- For **graduate-level** *(CPSC 6430)* the final accuracy of both algorithms on your test set should be higher than  <span style=\"color:red\">**85%**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                           TODO: Model Evaluation                           #\n",
    "##############################################################################\n",
    "pass\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you need to use the previous training and testing data file. \n",
    "\n",
    "You are **allowed** to use the svm functions in the **Scikit-learn** library and donâ€™t need to implement the algorithm from scratch.\n",
    "\n",
    "- You need to try at least **three** different kernel functions of SVM, and pick the **best** model.\n",
    "- You need to print out the final weights got from your best SVM model.\n",
    "\n",
    "**Note that:**\n",
    "- For **undergrads** *(CPSC 4430)* the final accuracy of both algorithms on your test set should be higher than  <span style=\"color:red\">**70%**</span>\n",
    "- For **graduate-level** *(CPSC 6430)* the final accuracy of both algorithms on your test set should be higher than  <span style=\"color:red\">**85%**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                      TODO: Classfication using SVM                         #\n",
    "##############################################################################\n",
    "# Pick the best model\n",
    "pass\n",
    "\n",
    "# Print out the final weights\n",
    "pass\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Decision Boundary and Model Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to plot the decision boundary of Logistic Regression and SVM that you previously trained separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                   TODO: Plot the Decision Boundary                         #\n",
    "##############################################################################\n",
    "pass\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your data and plot, you should then briefly discuss which one has better performance and why.\n",
    "\n",
    "**Your Answer:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
